trainer_type: fsdp2_trainer 
    
# Dataset configuration - now includes the actual dataset definitions
dataset_config:
  dataset_type: vision_iterable
  dataset_format: yaml
      
  # Inline dataset definitions
  # Download from: https://huggingface.co/datasets/longvideotool/LongVT-Parquet
  datasets:
    - path: longvideotool/LongVT-Parquet/longvt_sft_geminicot_4k8.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_geminicot_4k8.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_longvideoreason_5k2.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_videor1_165k5.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_tvg_6k3.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_longvideoreflection_3k.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_llavacot_54k5.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_openvlthinker_2k8.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_sft_wemath_602.parquet
      data_folder: ""
      data_type: parquet
    - path: longvideotool/LongVT-Parquet/longvt_rft_selftrace_15k3.parquet
      data_folder: ""
      data_type: parquet
      
  # Processor configuration
  processor_config:
    processor_name: "Qwen/Qwen2.5-VL-7B-Instruct"
    processor_type: "qwen2_5_vl"
      
  # Packing configuration
  packing: true
  packing_strategy: first_fit
  packing_length: 51200
  filter_overlong: true

  video_backend: qwen_vl_utils
  video_sampling_strategy: fps
  video_max_pixels: 50176
  video_max_frames: 512
    
# Model configuration
model_config:
  load_from_pretrained_path: "Qwen/Qwen2.5-VL-7B-Instruct"
  attn_implementation: "flash_attention_2"
    
# Training arguments, mostly compatible with HuggingFace Trainer
trainer_args:
  per_device_train_batch_size: 1
  learning_rate: 5.0e-05
  weight_decay: 0.0
  gradient_accumulation_steps: 1
  gradient_checkpointing: true
  num_train_epochs: 1
  max_steps: 1600
  save_steps: 400
  save_total_limit: 4
  report_to: "wandb"
  output_dir: "your_output_dir"
  warmup_ratio: 0.1
  run_name: "longvt_7b_sft"
  eval_strategy: "no"
  logging_steps: 1
  group_by_length: false 
  dataloader_num_workers: 4
  dataloader_prefetch_factor: 2
  bf16: true
  lr_scheduler_type: "cosine"
  use_liger_kernel: true
  use_rmpad: true
  torch_empty_cache_steps: 100
  fsdp2: true
  fsdp_config:
    transformer_layer_cls_to_wrap: ["Qwen2_5_VLDecoderLayer"]
    reshard_after_forward: false
  sp_ulysses_degree: 1
  enable_profiler: false
  profiler_config:
    start_step: 1
    end_step: 3
  